{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\paris_cite\\m2\\cours\\aide décision\\knowledge_distillation\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import lightning as L\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "import torch\n",
    "from torcheval.metrics import MulticlassF1Score\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "torch.set_float32_matmul_precision(\"medium\") # Take advantage of the tensor cores on the RTX GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A manual seed used for reproducibility throughout this notebook.\n",
    "MANUAL_SEED = 7\n",
    "# The number of epochs used for all training done in this notebook.\n",
    "EPOCHS = 10\n",
    "# The batch size used for all training done in this notebook.\n",
    "BATCH_SIZE = 4096 # As much as the GPU can handle for the biggest model.\n",
    "# The learning rate used for all training done in this notebook.\n",
    "LEARNINIG_RATE = 1e-3\n",
    "# The number of classes in the CIFAR10 dataset.\n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bat_resnext26ts',\n",
       " 'beit_base_patch16_224',\n",
       " 'beit_base_patch16_384',\n",
       " 'beit_large_patch16_224',\n",
       " 'beit_large_patch16_384',\n",
       " 'beit_large_patch16_512',\n",
       " 'beitv2_base_patch16_224',\n",
       " 'beitv2_large_patch16_224',\n",
       " 'botnet26t_256',\n",
       " 'botnet50ts_256',\n",
       " 'caformer_b36',\n",
       " 'caformer_m36',\n",
       " 'caformer_s18',\n",
       " 'caformer_s36',\n",
       " 'cait_m36_384',\n",
       " 'cait_m48_448',\n",
       " 'cait_s24_224',\n",
       " 'cait_s24_384',\n",
       " 'cait_s36_384',\n",
       " 'cait_xs24_384',\n",
       " 'cait_xxs24_224',\n",
       " 'cait_xxs24_384',\n",
       " 'cait_xxs36_224',\n",
       " 'cait_xxs36_384',\n",
       " 'coat_lite_medium',\n",
       " 'coat_lite_medium_384',\n",
       " 'coat_lite_mini',\n",
       " 'coat_lite_small',\n",
       " 'coat_lite_tiny',\n",
       " 'coat_mini',\n",
       " 'coat_small',\n",
       " 'coat_tiny',\n",
       " 'coatnet_0_224',\n",
       " 'coatnet_0_rw_224',\n",
       " 'coatnet_1_224',\n",
       " 'coatnet_1_rw_224',\n",
       " 'coatnet_2_224',\n",
       " 'coatnet_2_rw_224',\n",
       " 'coatnet_3_224',\n",
       " 'coatnet_3_rw_224',\n",
       " 'coatnet_4_224',\n",
       " 'coatnet_5_224',\n",
       " 'coatnet_bn_0_rw_224',\n",
       " 'coatnet_nano_cc_224',\n",
       " 'coatnet_nano_rw_224',\n",
       " 'coatnet_pico_rw_224',\n",
       " 'coatnet_rmlp_0_rw_224',\n",
       " 'coatnet_rmlp_1_rw2_224',\n",
       " 'coatnet_rmlp_1_rw_224',\n",
       " 'coatnet_rmlp_2_rw_224',\n",
       " 'coatnet_rmlp_2_rw_384',\n",
       " 'coatnet_rmlp_3_rw_224',\n",
       " 'coatnet_rmlp_nano_rw_224',\n",
       " 'coatnext_nano_rw_224',\n",
       " 'convformer_b36',\n",
       " 'convformer_m36',\n",
       " 'convformer_s18',\n",
       " 'convformer_s36',\n",
       " 'convit_base',\n",
       " 'convit_small',\n",
       " 'convit_tiny',\n",
       " 'convmixer_768_32',\n",
       " 'convmixer_1024_20_ks9_p14',\n",
       " 'convmixer_1536_20',\n",
       " 'convnext_atto',\n",
       " 'convnext_atto_ols',\n",
       " 'convnext_atto_rms',\n",
       " 'convnext_base',\n",
       " 'convnext_femto',\n",
       " 'convnext_femto_ols',\n",
       " 'convnext_large',\n",
       " 'convnext_large_mlp',\n",
       " 'convnext_nano',\n",
       " 'convnext_nano_ols',\n",
       " 'convnext_pico',\n",
       " 'convnext_pico_ols',\n",
       " 'convnext_small',\n",
       " 'convnext_tiny',\n",
       " 'convnext_tiny_hnf',\n",
       " 'convnext_xlarge',\n",
       " 'convnext_xxlarge',\n",
       " 'convnext_zepto_rms',\n",
       " 'convnext_zepto_rms_ols',\n",
       " 'convnextv2_atto',\n",
       " 'convnextv2_base',\n",
       " 'convnextv2_femto',\n",
       " 'convnextv2_huge',\n",
       " 'convnextv2_large',\n",
       " 'convnextv2_nano',\n",
       " 'convnextv2_pico',\n",
       " 'convnextv2_small',\n",
       " 'convnextv2_tiny',\n",
       " 'crossvit_9_240',\n",
       " 'crossvit_9_dagger_240',\n",
       " 'crossvit_15_240',\n",
       " 'crossvit_15_dagger_240',\n",
       " 'crossvit_15_dagger_408',\n",
       " 'crossvit_18_240',\n",
       " 'crossvit_18_dagger_240',\n",
       " 'crossvit_18_dagger_408',\n",
       " 'crossvit_base_240',\n",
       " 'crossvit_small_240',\n",
       " 'crossvit_tiny_240',\n",
       " 'cs3darknet_focus_l',\n",
       " 'cs3darknet_focus_m',\n",
       " 'cs3darknet_focus_s',\n",
       " 'cs3darknet_focus_x',\n",
       " 'cs3darknet_l',\n",
       " 'cs3darknet_m',\n",
       " 'cs3darknet_s',\n",
       " 'cs3darknet_x',\n",
       " 'cs3edgenet_x',\n",
       " 'cs3se_edgenet_x',\n",
       " 'cs3sedarknet_l',\n",
       " 'cs3sedarknet_x',\n",
       " 'cs3sedarknet_xdw',\n",
       " 'cspdarknet53',\n",
       " 'cspresnet50',\n",
       " 'cspresnet50d',\n",
       " 'cspresnet50w',\n",
       " 'cspresnext50',\n",
       " 'darknet17',\n",
       " 'darknet21',\n",
       " 'darknet53',\n",
       " 'darknetaa53',\n",
       " 'davit_base',\n",
       " 'davit_base_fl',\n",
       " 'davit_giant',\n",
       " 'davit_huge',\n",
       " 'davit_huge_fl',\n",
       " 'davit_large',\n",
       " 'davit_small',\n",
       " 'davit_tiny',\n",
       " 'deit3_base_patch16_224',\n",
       " 'deit3_base_patch16_384',\n",
       " 'deit3_huge_patch14_224',\n",
       " 'deit3_large_patch16_224',\n",
       " 'deit3_large_patch16_384',\n",
       " 'deit3_medium_patch16_224',\n",
       " 'deit3_small_patch16_224',\n",
       " 'deit3_small_patch16_384',\n",
       " 'deit_base_distilled_patch16_224',\n",
       " 'deit_base_distilled_patch16_384',\n",
       " 'deit_base_patch16_224',\n",
       " 'deit_base_patch16_384',\n",
       " 'deit_small_distilled_patch16_224',\n",
       " 'deit_small_patch16_224',\n",
       " 'deit_tiny_distilled_patch16_224',\n",
       " 'deit_tiny_patch16_224',\n",
       " 'densenet121',\n",
       " 'densenet161',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'densenet264d',\n",
       " 'densenetblur121d',\n",
       " 'dla34',\n",
       " 'dla46_c',\n",
       " 'dla46x_c',\n",
       " 'dla60',\n",
       " 'dla60_res2net',\n",
       " 'dla60_res2next',\n",
       " 'dla60x',\n",
       " 'dla60x_c',\n",
       " 'dla102',\n",
       " 'dla102x',\n",
       " 'dla102x2',\n",
       " 'dla169',\n",
       " 'dm_nfnet_f0',\n",
       " 'dm_nfnet_f1',\n",
       " 'dm_nfnet_f2',\n",
       " 'dm_nfnet_f3',\n",
       " 'dm_nfnet_f4',\n",
       " 'dm_nfnet_f5',\n",
       " 'dm_nfnet_f6',\n",
       " 'dpn48b',\n",
       " 'dpn68',\n",
       " 'dpn68b',\n",
       " 'dpn92',\n",
       " 'dpn98',\n",
       " 'dpn107',\n",
       " 'dpn131',\n",
       " 'eca_botnext26ts_256',\n",
       " 'eca_halonext26ts',\n",
       " 'eca_nfnet_l0',\n",
       " 'eca_nfnet_l1',\n",
       " 'eca_nfnet_l2',\n",
       " 'eca_nfnet_l3',\n",
       " 'eca_resnet33ts',\n",
       " 'eca_resnext26ts',\n",
       " 'eca_vovnet39b',\n",
       " 'ecaresnet26t',\n",
       " 'ecaresnet50d',\n",
       " 'ecaresnet50d_pruned',\n",
       " 'ecaresnet50t',\n",
       " 'ecaresnet101d',\n",
       " 'ecaresnet101d_pruned',\n",
       " 'ecaresnet200d',\n",
       " 'ecaresnet269d',\n",
       " 'ecaresnetlight',\n",
       " 'ecaresnext26t_32x4d',\n",
       " 'ecaresnext50t_32x4d',\n",
       " 'edgenext_base',\n",
       " 'edgenext_small',\n",
       " 'edgenext_small_rw',\n",
       " 'edgenext_x_small',\n",
       " 'edgenext_xx_small',\n",
       " 'efficientformer_l1',\n",
       " 'efficientformer_l3',\n",
       " 'efficientformer_l7',\n",
       " 'efficientformerv2_l',\n",
       " 'efficientformerv2_s0',\n",
       " 'efficientformerv2_s1',\n",
       " 'efficientformerv2_s2',\n",
       " 'efficientnet_b0',\n",
       " 'efficientnet_b0_g8_gn',\n",
       " 'efficientnet_b0_g16_evos',\n",
       " 'efficientnet_b0_gn',\n",
       " 'efficientnet_b1',\n",
       " 'efficientnet_b1_pruned',\n",
       " 'efficientnet_b2',\n",
       " 'efficientnet_b2_pruned',\n",
       " 'efficientnet_b3',\n",
       " 'efficientnet_b3_g8_gn',\n",
       " 'efficientnet_b3_gn',\n",
       " 'efficientnet_b3_pruned',\n",
       " 'efficientnet_b4',\n",
       " 'efficientnet_b5',\n",
       " 'efficientnet_b6',\n",
       " 'efficientnet_b7',\n",
       " 'efficientnet_b8',\n",
       " 'efficientnet_blur_b0',\n",
       " 'efficientnet_cc_b0_4e',\n",
       " 'efficientnet_cc_b0_8e',\n",
       " 'efficientnet_cc_b1_8e',\n",
       " 'efficientnet_el',\n",
       " 'efficientnet_el_pruned',\n",
       " 'efficientnet_em',\n",
       " 'efficientnet_es',\n",
       " 'efficientnet_es_pruned',\n",
       " 'efficientnet_h_b5',\n",
       " 'efficientnet_l2',\n",
       " 'efficientnet_lite0',\n",
       " 'efficientnet_lite1',\n",
       " 'efficientnet_lite2',\n",
       " 'efficientnet_lite3',\n",
       " 'efficientnet_lite4',\n",
       " 'efficientnet_x_b3',\n",
       " 'efficientnet_x_b5',\n",
       " 'efficientnetv2_l',\n",
       " 'efficientnetv2_m',\n",
       " 'efficientnetv2_rw_m',\n",
       " 'efficientnetv2_rw_s',\n",
       " 'efficientnetv2_rw_t',\n",
       " 'efficientnetv2_s',\n",
       " 'efficientnetv2_xl',\n",
       " 'efficientvit_b0',\n",
       " 'efficientvit_b1',\n",
       " 'efficientvit_b2',\n",
       " 'efficientvit_b3',\n",
       " 'efficientvit_l1',\n",
       " 'efficientvit_l2',\n",
       " 'efficientvit_l3',\n",
       " 'efficientvit_m0',\n",
       " 'efficientvit_m1',\n",
       " 'efficientvit_m2',\n",
       " 'efficientvit_m3',\n",
       " 'efficientvit_m4',\n",
       " 'efficientvit_m5',\n",
       " 'ese_vovnet19b_dw',\n",
       " 'ese_vovnet19b_slim',\n",
       " 'ese_vovnet19b_slim_dw',\n",
       " 'ese_vovnet39b',\n",
       " 'ese_vovnet39b_evos',\n",
       " 'ese_vovnet57b',\n",
       " 'ese_vovnet99b',\n",
       " 'eva02_base_patch14_224',\n",
       " 'eva02_base_patch14_448',\n",
       " 'eva02_base_patch16_clip_224',\n",
       " 'eva02_enormous_patch14_clip_224',\n",
       " 'eva02_large_patch14_224',\n",
       " 'eva02_large_patch14_448',\n",
       " 'eva02_large_patch14_clip_224',\n",
       " 'eva02_large_patch14_clip_336',\n",
       " 'eva02_small_patch14_224',\n",
       " 'eva02_small_patch14_336',\n",
       " 'eva02_tiny_patch14_224',\n",
       " 'eva02_tiny_patch14_336',\n",
       " 'eva_giant_patch14_224',\n",
       " 'eva_giant_patch14_336',\n",
       " 'eva_giant_patch14_560',\n",
       " 'eva_giant_patch14_clip_224',\n",
       " 'eva_large_patch14_196',\n",
       " 'eva_large_patch14_336',\n",
       " 'fastvit_ma36',\n",
       " 'fastvit_mci0',\n",
       " 'fastvit_mci1',\n",
       " 'fastvit_mci2',\n",
       " 'fastvit_s12',\n",
       " 'fastvit_sa12',\n",
       " 'fastvit_sa24',\n",
       " 'fastvit_sa36',\n",
       " 'fastvit_t8',\n",
       " 'fastvit_t12',\n",
       " 'fbnetc_100',\n",
       " 'fbnetv3_b',\n",
       " 'fbnetv3_d',\n",
       " 'fbnetv3_g',\n",
       " 'flexivit_base',\n",
       " 'flexivit_large',\n",
       " 'flexivit_small',\n",
       " 'focalnet_base_lrf',\n",
       " 'focalnet_base_srf',\n",
       " 'focalnet_huge_fl3',\n",
       " 'focalnet_huge_fl4',\n",
       " 'focalnet_large_fl3',\n",
       " 'focalnet_large_fl4',\n",
       " 'focalnet_small_lrf',\n",
       " 'focalnet_small_srf',\n",
       " 'focalnet_tiny_lrf',\n",
       " 'focalnet_tiny_srf',\n",
       " 'focalnet_xlarge_fl3',\n",
       " 'focalnet_xlarge_fl4',\n",
       " 'gc_efficientnetv2_rw_t',\n",
       " 'gcresnet33ts',\n",
       " 'gcresnet50t',\n",
       " 'gcresnext26ts',\n",
       " 'gcresnext50ts',\n",
       " 'gcvit_base',\n",
       " 'gcvit_small',\n",
       " 'gcvit_tiny',\n",
       " 'gcvit_xtiny',\n",
       " 'gcvit_xxtiny',\n",
       " 'gernet_l',\n",
       " 'gernet_m',\n",
       " 'gernet_s',\n",
       " 'ghostnet_050',\n",
       " 'ghostnet_100',\n",
       " 'ghostnet_130',\n",
       " 'ghostnetv2_100',\n",
       " 'ghostnetv2_130',\n",
       " 'ghostnetv2_160',\n",
       " 'gmixer_12_224',\n",
       " 'gmixer_24_224',\n",
       " 'gmlp_b16_224',\n",
       " 'gmlp_s16_224',\n",
       " 'gmlp_ti16_224',\n",
       " 'halo2botnet50ts_256',\n",
       " 'halonet26t',\n",
       " 'halonet50ts',\n",
       " 'halonet_h1',\n",
       " 'haloregnetz_b',\n",
       " 'hardcorenas_a',\n",
       " 'hardcorenas_b',\n",
       " 'hardcorenas_c',\n",
       " 'hardcorenas_d',\n",
       " 'hardcorenas_e',\n",
       " 'hardcorenas_f',\n",
       " 'hgnet_base',\n",
       " 'hgnet_small',\n",
       " 'hgnet_tiny',\n",
       " 'hgnetv2_b0',\n",
       " 'hgnetv2_b1',\n",
       " 'hgnetv2_b2',\n",
       " 'hgnetv2_b3',\n",
       " 'hgnetv2_b4',\n",
       " 'hgnetv2_b5',\n",
       " 'hgnetv2_b6',\n",
       " 'hiera_base_224',\n",
       " 'hiera_base_abswin_256',\n",
       " 'hiera_base_plus_224',\n",
       " 'hiera_huge_224',\n",
       " 'hiera_large_224',\n",
       " 'hiera_small_224',\n",
       " 'hiera_small_abswin_256',\n",
       " 'hiera_tiny_224',\n",
       " 'hieradet_small',\n",
       " 'hrnet_w18',\n",
       " 'hrnet_w18_small',\n",
       " 'hrnet_w18_small_v2',\n",
       " 'hrnet_w18_ssld',\n",
       " 'hrnet_w30',\n",
       " 'hrnet_w32',\n",
       " 'hrnet_w40',\n",
       " 'hrnet_w44',\n",
       " 'hrnet_w48',\n",
       " 'hrnet_w48_ssld',\n",
       " 'hrnet_w64',\n",
       " 'inception_next_base',\n",
       " 'inception_next_small',\n",
       " 'inception_next_tiny',\n",
       " 'inception_resnet_v2',\n",
       " 'inception_v3',\n",
       " 'inception_v4',\n",
       " 'lambda_resnet26rpt_256',\n",
       " 'lambda_resnet26t',\n",
       " 'lambda_resnet50ts',\n",
       " 'lamhalobotnet50ts_256',\n",
       " 'lcnet_035',\n",
       " 'lcnet_050',\n",
       " 'lcnet_075',\n",
       " 'lcnet_100',\n",
       " 'lcnet_150',\n",
       " 'legacy_senet154',\n",
       " 'legacy_seresnet18',\n",
       " 'legacy_seresnet34',\n",
       " 'legacy_seresnet50',\n",
       " 'legacy_seresnet101',\n",
       " 'legacy_seresnet152',\n",
       " 'legacy_seresnext26_32x4d',\n",
       " 'legacy_seresnext50_32x4d',\n",
       " 'legacy_seresnext101_32x4d',\n",
       " 'legacy_xception',\n",
       " 'levit_128',\n",
       " 'levit_128s',\n",
       " 'levit_192',\n",
       " 'levit_256',\n",
       " 'levit_256d',\n",
       " 'levit_384',\n",
       " 'levit_384_s8',\n",
       " 'levit_512',\n",
       " 'levit_512_s8',\n",
       " 'levit_512d',\n",
       " 'levit_conv_128',\n",
       " 'levit_conv_128s',\n",
       " 'levit_conv_192',\n",
       " 'levit_conv_256',\n",
       " 'levit_conv_256d',\n",
       " 'levit_conv_384',\n",
       " 'levit_conv_384_s8',\n",
       " 'levit_conv_512',\n",
       " 'levit_conv_512_s8',\n",
       " 'levit_conv_512d',\n",
       " 'mambaout_base',\n",
       " 'mambaout_base_plus_rw',\n",
       " 'mambaout_base_short_rw',\n",
       " 'mambaout_base_tall_rw',\n",
       " 'mambaout_base_wide_rw',\n",
       " 'mambaout_femto',\n",
       " 'mambaout_kobe',\n",
       " 'mambaout_small',\n",
       " 'mambaout_small_rw',\n",
       " 'mambaout_tiny',\n",
       " 'maxvit_base_tf_224',\n",
       " 'maxvit_base_tf_384',\n",
       " 'maxvit_base_tf_512',\n",
       " 'maxvit_large_tf_224',\n",
       " 'maxvit_large_tf_384',\n",
       " 'maxvit_large_tf_512',\n",
       " 'maxvit_nano_rw_256',\n",
       " 'maxvit_pico_rw_256',\n",
       " 'maxvit_rmlp_base_rw_224',\n",
       " 'maxvit_rmlp_base_rw_384',\n",
       " 'maxvit_rmlp_nano_rw_256',\n",
       " 'maxvit_rmlp_pico_rw_256',\n",
       " 'maxvit_rmlp_small_rw_224',\n",
       " 'maxvit_rmlp_small_rw_256',\n",
       " 'maxvit_rmlp_tiny_rw_256',\n",
       " 'maxvit_small_tf_224',\n",
       " 'maxvit_small_tf_384',\n",
       " 'maxvit_small_tf_512',\n",
       " 'maxvit_tiny_pm_256',\n",
       " 'maxvit_tiny_rw_224',\n",
       " 'maxvit_tiny_rw_256',\n",
       " 'maxvit_tiny_tf_224',\n",
       " 'maxvit_tiny_tf_384',\n",
       " 'maxvit_tiny_tf_512',\n",
       " 'maxvit_xlarge_tf_224',\n",
       " 'maxvit_xlarge_tf_384',\n",
       " 'maxvit_xlarge_tf_512',\n",
       " 'maxxvit_rmlp_nano_rw_256',\n",
       " 'maxxvit_rmlp_small_rw_256',\n",
       " 'maxxvit_rmlp_tiny_rw_256',\n",
       " 'maxxvitv2_nano_rw_256',\n",
       " 'maxxvitv2_rmlp_base_rw_224',\n",
       " 'maxxvitv2_rmlp_base_rw_384',\n",
       " 'maxxvitv2_rmlp_large_rw_224',\n",
       " 'mixer_b16_224',\n",
       " 'mixer_b32_224',\n",
       " 'mixer_l16_224',\n",
       " 'mixer_l32_224',\n",
       " 'mixer_s16_224',\n",
       " 'mixer_s32_224',\n",
       " 'mixnet_l',\n",
       " 'mixnet_m',\n",
       " 'mixnet_s',\n",
       " 'mixnet_xl',\n",
       " 'mixnet_xxl',\n",
       " 'mnasnet_050',\n",
       " 'mnasnet_075',\n",
       " 'mnasnet_100',\n",
       " 'mnasnet_140',\n",
       " 'mnasnet_small',\n",
       " 'mobilenet_edgetpu_100',\n",
       " 'mobilenet_edgetpu_v2_l',\n",
       " 'mobilenet_edgetpu_v2_m',\n",
       " 'mobilenet_edgetpu_v2_s',\n",
       " 'mobilenet_edgetpu_v2_xs',\n",
       " 'mobilenetv1_100',\n",
       " 'mobilenetv1_100h',\n",
       " 'mobilenetv1_125',\n",
       " 'mobilenetv2_035',\n",
       " 'mobilenetv2_050',\n",
       " 'mobilenetv2_075',\n",
       " 'mobilenetv2_100',\n",
       " 'mobilenetv2_110d',\n",
       " 'mobilenetv2_120d',\n",
       " 'mobilenetv2_140',\n",
       " 'mobilenetv3_large_075',\n",
       " 'mobilenetv3_large_100',\n",
       " 'mobilenetv3_large_150d',\n",
       " 'mobilenetv3_rw',\n",
       " 'mobilenetv3_small_050',\n",
       " 'mobilenetv3_small_075',\n",
       " 'mobilenetv3_small_100',\n",
       " 'mobilenetv4_conv_aa_large',\n",
       " 'mobilenetv4_conv_aa_medium',\n",
       " 'mobilenetv4_conv_blur_medium',\n",
       " 'mobilenetv4_conv_large',\n",
       " 'mobilenetv4_conv_medium',\n",
       " 'mobilenetv4_conv_small',\n",
       " 'mobilenetv4_conv_small_035',\n",
       " 'mobilenetv4_conv_small_050',\n",
       " 'mobilenetv4_hybrid_large',\n",
       " 'mobilenetv4_hybrid_large_075',\n",
       " 'mobilenetv4_hybrid_medium',\n",
       " 'mobilenetv4_hybrid_medium_075',\n",
       " 'mobileone_s0',\n",
       " 'mobileone_s1',\n",
       " 'mobileone_s2',\n",
       " 'mobileone_s3',\n",
       " 'mobileone_s4',\n",
       " 'mobilevit_s',\n",
       " 'mobilevit_xs',\n",
       " 'mobilevit_xxs',\n",
       " 'mobilevitv2_050',\n",
       " 'mobilevitv2_075',\n",
       " 'mobilevitv2_100',\n",
       " 'mobilevitv2_125',\n",
       " 'mobilevitv2_150',\n",
       " 'mobilevitv2_175',\n",
       " 'mobilevitv2_200',\n",
       " 'mvitv2_base',\n",
       " 'mvitv2_base_cls',\n",
       " 'mvitv2_huge_cls',\n",
       " 'mvitv2_large',\n",
       " 'mvitv2_large_cls',\n",
       " 'mvitv2_small',\n",
       " 'mvitv2_small_cls',\n",
       " 'mvitv2_tiny',\n",
       " 'nasnetalarge',\n",
       " 'nest_base',\n",
       " 'nest_base_jx',\n",
       " 'nest_small',\n",
       " 'nest_small_jx',\n",
       " 'nest_tiny',\n",
       " 'nest_tiny_jx',\n",
       " 'nextvit_base',\n",
       " 'nextvit_large',\n",
       " 'nextvit_small',\n",
       " 'nf_ecaresnet26',\n",
       " 'nf_ecaresnet50',\n",
       " 'nf_ecaresnet101',\n",
       " 'nf_regnet_b0',\n",
       " 'nf_regnet_b1',\n",
       " 'nf_regnet_b2',\n",
       " 'nf_regnet_b3',\n",
       " 'nf_regnet_b4',\n",
       " 'nf_regnet_b5',\n",
       " 'nf_resnet26',\n",
       " 'nf_resnet50',\n",
       " 'nf_resnet101',\n",
       " 'nf_seresnet26',\n",
       " 'nf_seresnet50',\n",
       " 'nf_seresnet101',\n",
       " 'nfnet_f0',\n",
       " 'nfnet_f1',\n",
       " 'nfnet_f2',\n",
       " 'nfnet_f3',\n",
       " 'nfnet_f4',\n",
       " 'nfnet_f5',\n",
       " 'nfnet_f6',\n",
       " 'nfnet_f7',\n",
       " 'nfnet_l0',\n",
       " 'pit_b_224',\n",
       " 'pit_b_distilled_224',\n",
       " 'pit_s_224',\n",
       " 'pit_s_distilled_224',\n",
       " 'pit_ti_224',\n",
       " 'pit_ti_distilled_224',\n",
       " 'pit_xs_224',\n",
       " 'pit_xs_distilled_224',\n",
       " 'pnasnet5large',\n",
       " 'poolformer_m36',\n",
       " 'poolformer_m48',\n",
       " 'poolformer_s12',\n",
       " 'poolformer_s24',\n",
       " 'poolformer_s36',\n",
       " 'poolformerv2_m36',\n",
       " 'poolformerv2_m48',\n",
       " 'poolformerv2_s12',\n",
       " 'poolformerv2_s24',\n",
       " 'poolformerv2_s36',\n",
       " 'pvt_v2_b0',\n",
       " 'pvt_v2_b1',\n",
       " 'pvt_v2_b2',\n",
       " 'pvt_v2_b2_li',\n",
       " 'pvt_v2_b3',\n",
       " 'pvt_v2_b4',\n",
       " 'pvt_v2_b5',\n",
       " 'rdnet_base',\n",
       " 'rdnet_large',\n",
       " 'rdnet_small',\n",
       " 'rdnet_tiny',\n",
       " 'regnetv_040',\n",
       " 'regnetv_064',\n",
       " 'regnetx_002',\n",
       " 'regnetx_004',\n",
       " 'regnetx_004_tv',\n",
       " 'regnetx_006',\n",
       " 'regnetx_008',\n",
       " 'regnetx_016',\n",
       " 'regnetx_032',\n",
       " 'regnetx_040',\n",
       " 'regnetx_064',\n",
       " 'regnetx_080',\n",
       " 'regnetx_120',\n",
       " 'regnetx_160',\n",
       " 'regnetx_320',\n",
       " 'regnety_002',\n",
       " 'regnety_004',\n",
       " 'regnety_006',\n",
       " 'regnety_008',\n",
       " 'regnety_008_tv',\n",
       " 'regnety_016',\n",
       " 'regnety_032',\n",
       " 'regnety_040',\n",
       " 'regnety_040_sgn',\n",
       " 'regnety_064',\n",
       " 'regnety_080',\n",
       " 'regnety_080_tv',\n",
       " 'regnety_120',\n",
       " 'regnety_160',\n",
       " 'regnety_320',\n",
       " 'regnety_640',\n",
       " 'regnety_1280',\n",
       " 'regnety_2560',\n",
       " 'regnetz_005',\n",
       " 'regnetz_040',\n",
       " 'regnetz_040_h',\n",
       " 'regnetz_b16',\n",
       " 'regnetz_b16_evos',\n",
       " 'regnetz_c16',\n",
       " 'regnetz_c16_evos',\n",
       " 'regnetz_d8',\n",
       " 'regnetz_d8_evos',\n",
       " 'regnetz_d32',\n",
       " 'regnetz_e8',\n",
       " 'repghostnet_050',\n",
       " 'repghostnet_058',\n",
       " 'repghostnet_080',\n",
       " 'repghostnet_100',\n",
       " 'repghostnet_111',\n",
       " 'repghostnet_130',\n",
       " 'repghostnet_150',\n",
       " 'repghostnet_200',\n",
       " 'repvgg_a0',\n",
       " 'repvgg_a1',\n",
       " 'repvgg_a2',\n",
       " 'repvgg_b0',\n",
       " 'repvgg_b1',\n",
       " 'repvgg_b1g4',\n",
       " 'repvgg_b2',\n",
       " 'repvgg_b2g4',\n",
       " 'repvgg_b3',\n",
       " 'repvgg_b3g4',\n",
       " 'repvgg_d2se',\n",
       " 'repvit_m0_9',\n",
       " 'repvit_m1',\n",
       " 'repvit_m1_0',\n",
       " 'repvit_m1_1',\n",
       " 'repvit_m1_5',\n",
       " 'repvit_m2',\n",
       " 'repvit_m2_3',\n",
       " 'repvit_m3',\n",
       " 'res2net50_14w_8s',\n",
       " 'res2net50_26w_4s',\n",
       " 'res2net50_26w_6s',\n",
       " 'res2net50_26w_8s',\n",
       " 'res2net50_48w_2s',\n",
       " 'res2net50d',\n",
       " 'res2net101_26w_4s',\n",
       " 'res2net101d',\n",
       " 'res2next50',\n",
       " 'resmlp_12_224',\n",
       " 'resmlp_24_224',\n",
       " 'resmlp_36_224',\n",
       " 'resmlp_big_24_224',\n",
       " 'resnest14d',\n",
       " 'resnest26d',\n",
       " 'resnest50d',\n",
       " 'resnest50d_1s4x24d',\n",
       " 'resnest50d_4s2x40d',\n",
       " 'resnest101e',\n",
       " 'resnest200e',\n",
       " 'resnest269e',\n",
       " 'resnet10t',\n",
       " 'resnet14t',\n",
       " 'resnet18',\n",
       " 'resnet18d',\n",
       " 'resnet26',\n",
       " 'resnet26d',\n",
       " 'resnet26t',\n",
       " 'resnet32ts',\n",
       " 'resnet33ts',\n",
       " 'resnet34',\n",
       " 'resnet34d',\n",
       " 'resnet50',\n",
       " 'resnet50_clip',\n",
       " 'resnet50_clip_gap',\n",
       " 'resnet50_gn',\n",
       " 'resnet50_mlp',\n",
       " 'resnet50c',\n",
       " 'resnet50d',\n",
       " 'resnet50s',\n",
       " 'resnet50t',\n",
       " 'resnet50x4_clip',\n",
       " 'resnet50x4_clip_gap',\n",
       " 'resnet50x16_clip',\n",
       " 'resnet50x16_clip_gap',\n",
       " 'resnet50x64_clip',\n",
       " 'resnet50x64_clip_gap',\n",
       " 'resnet51q',\n",
       " 'resnet61q',\n",
       " 'resnet101',\n",
       " 'resnet101_clip',\n",
       " 'resnet101_clip_gap',\n",
       " 'resnet101c',\n",
       " 'resnet101d',\n",
       " 'resnet101s',\n",
       " 'resnet152',\n",
       " 'resnet152c',\n",
       " 'resnet152d',\n",
       " 'resnet152s',\n",
       " 'resnet200',\n",
       " 'resnet200d',\n",
       " 'resnetaa34d',\n",
       " 'resnetaa50',\n",
       " 'resnetaa50d',\n",
       " 'resnetaa101d',\n",
       " 'resnetblur18',\n",
       " 'resnetblur50',\n",
       " 'resnetblur50d',\n",
       " 'resnetblur101d',\n",
       " 'resnetrs50',\n",
       " 'resnetrs101',\n",
       " 'resnetrs152',\n",
       " 'resnetrs200',\n",
       " 'resnetrs270',\n",
       " 'resnetrs350',\n",
       " 'resnetrs420',\n",
       " 'resnetv2_18',\n",
       " 'resnetv2_18d',\n",
       " 'resnetv2_34',\n",
       " 'resnetv2_34d',\n",
       " 'resnetv2_50',\n",
       " 'resnetv2_50d',\n",
       " 'resnetv2_50d_evos',\n",
       " 'resnetv2_50d_frn',\n",
       " 'resnetv2_50d_gn',\n",
       " 'resnetv2_50t',\n",
       " 'resnetv2_50x1_bit',\n",
       " 'resnetv2_50x3_bit',\n",
       " 'resnetv2_101',\n",
       " 'resnetv2_101d',\n",
       " 'resnetv2_101x1_bit',\n",
       " 'resnetv2_101x3_bit',\n",
       " 'resnetv2_152',\n",
       " 'resnetv2_152d',\n",
       " 'resnetv2_152x2_bit',\n",
       " 'resnetv2_152x4_bit',\n",
       " 'resnext26ts',\n",
       " 'resnext50_32x4d',\n",
       " 'resnext50d_32x4d',\n",
       " 'resnext101_32x4d',\n",
       " 'resnext101_32x8d',\n",
       " 'resnext101_32x16d',\n",
       " 'resnext101_32x32d',\n",
       " 'resnext101_64x4d',\n",
       " 'rexnet_100',\n",
       " 'rexnet_130',\n",
       " 'rexnet_150',\n",
       " 'rexnet_200',\n",
       " 'rexnet_300',\n",
       " 'rexnetr_100',\n",
       " 'rexnetr_130',\n",
       " 'rexnetr_150',\n",
       " 'rexnetr_200',\n",
       " 'rexnetr_300',\n",
       " 'sam2_hiera_base_plus',\n",
       " 'sam2_hiera_large',\n",
       " 'sam2_hiera_small',\n",
       " 'sam2_hiera_tiny',\n",
       " 'samvit_base_patch16',\n",
       " 'samvit_base_patch16_224',\n",
       " 'samvit_huge_patch16',\n",
       " 'samvit_large_patch16',\n",
       " 'sebotnet33ts_256',\n",
       " 'sedarknet21',\n",
       " 'sehalonet33ts',\n",
       " 'selecsls42',\n",
       " 'selecsls42b',\n",
       " 'selecsls60',\n",
       " 'selecsls60b',\n",
       " 'selecsls84',\n",
       " 'semnasnet_050',\n",
       " 'semnasnet_075',\n",
       " 'semnasnet_100',\n",
       " 'semnasnet_140',\n",
       " 'senet154',\n",
       " 'sequencer2d_l',\n",
       " 'sequencer2d_m',\n",
       " 'sequencer2d_s',\n",
       " 'seresnet18',\n",
       " 'seresnet33ts',\n",
       " 'seresnet34',\n",
       " 'seresnet50',\n",
       " 'seresnet50t',\n",
       " 'seresnet101',\n",
       " 'seresnet152',\n",
       " 'seresnet152d',\n",
       " 'seresnet200d',\n",
       " 'seresnet269d',\n",
       " 'seresnetaa50d',\n",
       " 'seresnext26d_32x4d',\n",
       " 'seresnext26t_32x4d',\n",
       " 'seresnext26ts',\n",
       " 'seresnext50_32x4d',\n",
       " 'seresnext101_32x4d',\n",
       " 'seresnext101_32x8d',\n",
       " 'seresnext101_64x4d',\n",
       " 'seresnext101d_32x8d',\n",
       " 'seresnextaa101d_32x8d',\n",
       " 'seresnextaa201d_32x8d',\n",
       " 'skresnet18',\n",
       " 'skresnet34',\n",
       " 'skresnet50',\n",
       " 'skresnet50d',\n",
       " 'skresnext50_32x4d',\n",
       " 'spnasnet_100',\n",
       " 'swin_base_patch4_window7_224',\n",
       " 'swin_base_patch4_window12_384',\n",
       " 'swin_large_patch4_window7_224',\n",
       " 'swin_large_patch4_window12_384',\n",
       " 'swin_s3_base_224',\n",
       " 'swin_s3_small_224',\n",
       " 'swin_s3_tiny_224',\n",
       " 'swin_small_patch4_window7_224',\n",
       " 'swin_tiny_patch4_window7_224',\n",
       " 'swinv2_base_window8_256',\n",
       " 'swinv2_base_window12_192',\n",
       " 'swinv2_base_window12to16_192to256',\n",
       " 'swinv2_base_window12to24_192to384',\n",
       " 'swinv2_base_window16_256',\n",
       " 'swinv2_cr_base_224',\n",
       " 'swinv2_cr_base_384',\n",
       " 'swinv2_cr_base_ns_224',\n",
       " 'swinv2_cr_giant_224',\n",
       " 'swinv2_cr_giant_384',\n",
       " 'swinv2_cr_huge_224',\n",
       " 'swinv2_cr_huge_384',\n",
       " 'swinv2_cr_large_224',\n",
       " 'swinv2_cr_large_384',\n",
       " 'swinv2_cr_small_224',\n",
       " 'swinv2_cr_small_384',\n",
       " 'swinv2_cr_small_ns_224',\n",
       " 'swinv2_cr_small_ns_256',\n",
       " 'swinv2_cr_tiny_224',\n",
       " 'swinv2_cr_tiny_384',\n",
       " 'swinv2_cr_tiny_ns_224',\n",
       " 'swinv2_large_window12_192',\n",
       " 'swinv2_large_window12to16_192to256',\n",
       " 'swinv2_large_window12to24_192to384',\n",
       " 'swinv2_small_window8_256',\n",
       " 'swinv2_small_window16_256',\n",
       " 'swinv2_tiny_window8_256',\n",
       " 'swinv2_tiny_window16_256',\n",
       " 'test_byobnet',\n",
       " 'test_convnext',\n",
       " 'test_convnext2',\n",
       " 'test_convnext3',\n",
       " 'test_efficientnet',\n",
       " 'test_efficientnet_evos',\n",
       " 'test_efficientnet_gn',\n",
       " 'test_efficientnet_ln',\n",
       " 'test_mambaout',\n",
       " 'test_nfnet',\n",
       " 'test_resnet',\n",
       " 'test_vit',\n",
       " 'test_vit2',\n",
       " 'test_vit3',\n",
       " 'tf_efficientnet_b0',\n",
       " 'tf_efficientnet_b1',\n",
       " 'tf_efficientnet_b2',\n",
       " 'tf_efficientnet_b3',\n",
       " 'tf_efficientnet_b4',\n",
       " 'tf_efficientnet_b5',\n",
       " 'tf_efficientnet_b6',\n",
       " 'tf_efficientnet_b7',\n",
       " 'tf_efficientnet_b8',\n",
       " 'tf_efficientnet_cc_b0_4e',\n",
       " 'tf_efficientnet_cc_b0_8e',\n",
       " 'tf_efficientnet_cc_b1_8e',\n",
       " 'tf_efficientnet_el',\n",
       " 'tf_efficientnet_em',\n",
       " 'tf_efficientnet_es',\n",
       " 'tf_efficientnet_l2',\n",
       " 'tf_efficientnet_lite0',\n",
       " 'tf_efficientnet_lite1',\n",
       " 'tf_efficientnet_lite2',\n",
       " 'tf_efficientnet_lite3',\n",
       " 'tf_efficientnet_lite4',\n",
       " 'tf_efficientnetv2_b0',\n",
       " 'tf_efficientnetv2_b1',\n",
       " 'tf_efficientnetv2_b2',\n",
       " 'tf_efficientnetv2_b3',\n",
       " 'tf_efficientnetv2_l',\n",
       " 'tf_efficientnetv2_m',\n",
       " 'tf_efficientnetv2_s',\n",
       " 'tf_efficientnetv2_xl',\n",
       " 'tf_mixnet_l',\n",
       " 'tf_mixnet_m',\n",
       " 'tf_mixnet_s',\n",
       " 'tf_mobilenetv3_large_075',\n",
       " 'tf_mobilenetv3_large_100',\n",
       " 'tf_mobilenetv3_large_minimal_100',\n",
       " 'tf_mobilenetv3_small_075',\n",
       " 'tf_mobilenetv3_small_100',\n",
       " 'tf_mobilenetv3_small_minimal_100',\n",
       " 'tiny_vit_5m_224',\n",
       " 'tiny_vit_11m_224',\n",
       " 'tiny_vit_21m_224',\n",
       " 'tiny_vit_21m_384',\n",
       " 'tiny_vit_21m_512',\n",
       " 'tinynet_a',\n",
       " 'tinynet_b',\n",
       " 'tinynet_c',\n",
       " 'tinynet_d',\n",
       " 'tinynet_e',\n",
       " 'tnt_b_patch16_224',\n",
       " 'tnt_s_patch16_224',\n",
       " 'tresnet_l',\n",
       " 'tresnet_m',\n",
       " 'tresnet_v2_l',\n",
       " 'tresnet_xl',\n",
       " 'twins_pcpvt_base',\n",
       " 'twins_pcpvt_large',\n",
       " 'twins_pcpvt_small',\n",
       " 'twins_svt_base',\n",
       " 'twins_svt_large',\n",
       " 'twins_svt_small',\n",
       " 'vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19',\n",
       " 'vgg19_bn',\n",
       " 'visformer_small',\n",
       " 'visformer_tiny',\n",
       " 'vit_base_mci_224',\n",
       " 'vit_base_patch8_224',\n",
       " 'vit_base_patch14_dinov2',\n",
       " 'vit_base_patch14_reg4_dinov2',\n",
       " 'vit_base_patch16_18x2_224',\n",
       " 'vit_base_patch16_224',\n",
       " 'vit_base_patch16_224_miil',\n",
       " 'vit_base_patch16_384',\n",
       " 'vit_base_patch16_clip_224',\n",
       " 'vit_base_patch16_clip_384',\n",
       " 'vit_base_patch16_clip_quickgelu_224',\n",
       " 'vit_base_patch16_gap_224',\n",
       " 'vit_base_patch16_plus_240',\n",
       " 'vit_base_patch16_plus_clip_240',\n",
       " 'vit_base_patch16_reg4_gap_256',\n",
       " 'vit_base_patch16_rope_reg1_gap_256',\n",
       " 'vit_base_patch16_rpn_224',\n",
       " 'vit_base_patch16_siglip_224',\n",
       " 'vit_base_patch16_siglip_256',\n",
       " 'vit_base_patch16_siglip_384',\n",
       " 'vit_base_patch16_siglip_512',\n",
       " 'vit_base_patch16_siglip_gap_224',\n",
       " 'vit_base_patch16_siglip_gap_256',\n",
       " 'vit_base_patch16_siglip_gap_384',\n",
       " 'vit_base_patch16_siglip_gap_512',\n",
       " 'vit_base_patch16_xp_224',\n",
       " 'vit_base_patch32_224',\n",
       " 'vit_base_patch32_384',\n",
       " 'vit_base_patch32_clip_224',\n",
       " 'vit_base_patch32_clip_256',\n",
       " ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Timm is a library for loading pre-trained (or not) models. \n",
    "timm.list_models() #Lists the IDs of the available models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gotta extract the model code into nn.module\n",
    "# then build a lightning module to handle the training pipeline\n",
    "# Then throw away this lightning module and create a new one for distillation\n",
    "# Load the model using .load_state_dict() like shown here : https://github.com/Lightning-AI/pytorch-lightning/issues/20053#issuecomment-2215485554"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeacherResNet50(torch.nn.Module):\n",
    "    def __init__(self, num_classes : int, pretrained: bool = True) -> None:\n",
    "        \"\"\"An implementation of a fine-tunable Resnet50 pretrained (or not) model.\n",
    "        The final classification layer is replaced with a new one that predicts the number of classes defined by 'num_classes'.\n",
    "\n",
    "        Args:\n",
    "            num_classes: The number of classes to set when replacing the final classification layer for fine-tuning purposes.\n",
    "            pretrained: A boolean value indicating whether to load the pre-trained weights of the model. Defaults to true.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.resnet50 = timm.create_model('resnet50', pretrained=pretrained)\n",
    "        #Replace the final classification layer of the model for fine-tuning purposes.\n",
    "        self.resnet50.fc = torch.nn.Linear(\n",
    "            in_features=self.resnet50.fc.in_features,\n",
    "            out_features=num_classes\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.resnet50(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StudentResNet18(torch.nn.Module):\n",
    "    def __init__(self, num_classes : int, pretrained: bool = True) -> None:\n",
    "        \"\"\"An implementation of a fine-tunable Resnet18 pretrained (or not) model.\n",
    "        The final classification layer is replaced with a new one that predicts the number of classes defined by 'num_classes'.\n",
    "\n",
    "        Args:\n",
    "            num_classes: The number of classes to set when replacing the final classification layer for fine-tuning purposes.\n",
    "            pretrained: A boolean value indicating whether to load the pre-trained weights of the model. Defaults to true.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.resnet18 = timm.create_model('resnet18', pretrained=pretrained)\n",
    "        #Replace the final classification layer of the model for fine-tuning purposes.\n",
    "        self.resnet18.fc = torch.nn.Linear(\n",
    "            in_features=self.resnet18.fc.in_features,\n",
    "            out_features=num_classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet18(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingTeacherResNet50(L.LightningModule):\n",
    "    def __init__(self, num_classes : int, pretrained: bool = True, lr : float = 1e-4) -> None:\n",
    "        \"\"\"A pytorch lightning implementation of the Resnet50 fine-tuning process.\n",
    "\n",
    "        Args:\n",
    "            num_classes: The number of classes to set when replacing the final classification layer for fine-tuning purposes.\n",
    "            pretrained: A boolean value indicating whether to load the pre-trained weights of the model. Defaults to true.\n",
    "            lr: The learning rate used during training. Defaults to 1e-4.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.resnet50 = TeacherResNet50(num_classes=num_classes,\n",
    "                                        pretrained=pretrained)\n",
    "        self.lr = lr\n",
    "        self.f1_metric = MulticlassF1Score(num_classes=num_classes)\n",
    "\n",
    "    def forward(self, input_tensor: torch.Tensor) -> torch.Tensor:\n",
    "        return self.resnet50(input_tensor)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        input_batch, target_batch = batch\n",
    "        logits = self(input_batch).squeeze()\n",
    "        loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "        #Calculate metrics\n",
    "        self.f1_metric.update(logits, target_batch)\n",
    "        train_f1_score = self.f1_metric.compute()\n",
    "        self.log(\"train_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train_f1_score\", train_f1_score, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # validation_step defines the validation loop.\n",
    "        input_batch, target_batch = batch\n",
    "        logits = self(input_batch).squeeze()\n",
    "        loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "        #Calculate metrics\n",
    "        self.f1_metric.update(logits, target_batch)\n",
    "        validation_f1_score = self.f1_metric.compute()\n",
    "        self.log(\"validation_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"validation_f1_score\", validation_f1_score, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # test_step defines the test loop.\n",
    "        input_batch, target_batch = batch\n",
    "        logits = self(input_batch).squeeze()\n",
    "        loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "        #Calculate metrics\n",
    "        self.f1_metric.update(logits, target_batch)\n",
    "        test_f1_score = self.f1_metric.compute()\n",
    "        self.log(\"test_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"test_f1_score\", test_f1_score, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingStudentResNet18(L.LightningModule):\n",
    "    def __init__(self, num_classes : int, pretrained: bool = True, lr : float = 1e-4) -> None:\n",
    "        \"\"\"A pytorch lightning implementation of the Resnet18 pretrained model.\n",
    "\n",
    "        Args:\n",
    "            num_classes: The number of classes to set when replacing the final classification layer for fine-tuning purposes.\n",
    "            pretrained: A boolean value indicating whether to load the pre-trained weights of the model. Defaults to true.\n",
    "            lr: The learning rate used during training. Defaults to 1e-4.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.resnet18 = StudentResNet18(num_classes=num_classes,\n",
    "                                        pretrained=pretrained)\n",
    "        self.lr = lr\n",
    "        self.f1_metric = MulticlassF1Score(num_classes=num_classes)\n",
    "\n",
    "    def forward(self, input_tensor: torch.Tensor) -> torch.Tensor:\n",
    "        return self.resnet18(input_tensor)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        input_batch, target_batch = batch\n",
    "        logits = self(input_batch).squeeze()\n",
    "        loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "        #Calculate metrics\n",
    "        self.f1_metric.update(logits, target_batch)\n",
    "        train_f1_score = self.f1_metric.compute()\n",
    "        self.log(\"train_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train_f1_score\", train_f1_score, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # validation_step defines the validation loop.\n",
    "        input_batch, target_batch = batch\n",
    "        logits = self(input_batch).squeeze()\n",
    "        loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "        #Calculate metrics\n",
    "        self.f1_metric.update(logits, target_batch)\n",
    "        validation_f1_score = self.f1_metric.compute()\n",
    "        self.log(\"validation_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"validation_f1_score\", validation_f1_score, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # test_step defines the test loop.\n",
    "        input_batch, target_batch = batch\n",
    "        logits = self(input_batch).squeeze()\n",
    "        loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "        #Calculate metrics\n",
    "        self.f1_metric.update(logits, target_batch)\n",
    "        test_f1_score = self.f1_metric.compute()\n",
    "        self.log(\"test_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"test_f1_score\", test_f1_score, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Cifar10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    #TODO : Consider resizing the images to 224x224 ? maybe it could improve performance ?\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Load the training and test datasets.\n",
    "train_dataset = datasets.CIFAR10(root=\"./CIFAR10\", train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root=\"./CIFAR10\", train=False, download=True, transform=transform)\n",
    "\n",
    "# Create a validation set from the training set (80% train, 20% validation).\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "validation_size = len(train_dataset) - train_size\n",
    "#Use a manual seed for reproducibility.\n",
    "generator = torch.Generator().manual_seed(MANUAL_SEED)\n",
    "train_dataset, validation_dataset = random_split(train_dataset, [train_size, validation_size], generator=generator)\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune the teacher model on the CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the pre-trained teacher model with 10 classes for the classifier.\n",
    "torch.manual_seed(MANUAL_SEED) # Seed the weights for the new classification layer.\n",
    "teacherResnet50 = TrainingTeacherResNet50(num_classes=NUM_CLASSES,\n",
    "                                  pretrained=True,\n",
    "                                  lr=LEARNINIG_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1)` was configured so validation will run after every batch.\n"
     ]
    }
   ],
   "source": [
    "# Only save to disk the best performing version of the model throughout training (best f1 score).\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=\"models/pretrained_teacher_training\",\n",
    "        monitor=\"validation_f1_score\",\n",
    "        filename=\"best\",\n",
    "        mode=\"max\",\n",
    "        save_last=False,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "trainer = L.Trainer(max_epochs=EPOCHS,\n",
    "                    log_every_n_steps=1,\n",
    "                    val_check_interval=1,\n",
    "                    callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type            | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | resnet50 | TeacherResNet50 | 23.5 M | train\n",
      "-----------------------------------------------------\n",
      "23.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.114    Total estimated model params size (MB)\n",
      "218       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\paris_cite\\m2\\cours\\aide décision\\knowledge_distillation\\venv\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\paris_cite\\m2\\cours\\aide décision\\knowledge_distillation\\venv\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/10 [00:00<?, ?it/s] "
     ]
    }
   ],
   "source": [
    "trainer.fit(model=teacherResnet50, train_dataloaders=train_dataloader, val_dataloaders=validation_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\paris_cite\\m2\\cours\\aide décision\\knowledge_distillation\\venv\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_f1_score         0.7022854685783386\n",
      "        test_loss           1.0286998748779297\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 1.0286998748779297, 'test_f1_score': 0.7022854685783386}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the teacher model.\n",
    "trainer.test(model=teacherResnet50, dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of parameters for the teacher Resnet50 (extracted from training output).\n",
    "#   | Name     | Type   | Params | Mode \n",
    "# --------------------------------------------\n",
    "# 0 | resnet50 | ResNet | 23.5 M | train\n",
    "# --------------------------------------------\n",
    "# 23.5 M    Trainable params\n",
    "# 0         Non-trainable params\n",
    "# 23.5 M    Total params\n",
    "# 94.114    Total estimated model params size (MB)\n",
    "# 217       Modules in train mode\n",
    "# 0         Modules in eval mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategy 1 : Knowledge distillation using a pre-trained student"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune the pre-trained student network on CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the pre-trained student model with 10 classes for the classifier.\n",
    "torch.manual_seed(MANUAL_SEED) # Seed the weights for the new classification layer.\n",
    "studentResnet18 = TrainingStudentResNet18(num_classes=10,\n",
    "                                  pretrained=True,\n",
    "                                  lr=LEARNINIG_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1)` was configured so validation will run after every batch.\n"
     ]
    }
   ],
   "source": [
    "# Only save to disk the best performing version of the model throughout training (best f1 score).\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=\"models/pretrained_student_training\",\n",
    "        monitor=\"validation_f1_score\",\n",
    "        filename=\"best\",\n",
    "        mode=\"max\",\n",
    "        save_last=False,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "trainer = L.Trainer(max_epochs=EPOCHS,\n",
    "                    log_every_n_steps=1,\n",
    "                    val_check_interval=1,\n",
    "                    callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type            | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | resnet18 | StudentResNet18 | 11.2 M | train\n",
      "-----------------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.727    Total estimated model params size (MB)\n",
      "95        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 10/10 [00:22<00:00,  0.45it/s, v_num=1, train_loss_step=1.940, train_f1_score_step=0.231, validation_loss=1.820, validation_f1_score=0.239, train_loss_epoch=2.170, train_f1_score_epoch=0.153]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 10: 'validation_f1_score' reached 0.23864 (best 0.23864), saving model to 'C:\\\\paris_cite\\\\m2\\\\cours\\\\aide décision\\\\knowledge_distillation\\\\models\\\\pretrained_student_training\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 10/10 [00:23<00:00,  0.42it/s, v_num=1, train_loss_step=1.360, train_f1_score_step=0.348, validation_loss=1.510, validation_f1_score=0.352, train_loss_epoch=1.600, train_f1_score_epoch=0.302]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 20: 'validation_f1_score' reached 0.35198 (best 0.35198), saving model to 'C:\\\\paris_cite\\\\m2\\\\cours\\\\aide décision\\\\knowledge_distillation\\\\models\\\\pretrained_student_training\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 10/10 [00:23<00:00,  0.42it/s, v_num=1, train_loss_step=1.030, train_f1_score_step=0.422, validation_loss=1.240, validation_f1_score=0.424, train_loss_epoch=1.120, train_f1_score_epoch=0.390]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 30: 'validation_f1_score' reached 0.42441 (best 0.42441), saving model to 'C:\\\\paris_cite\\\\m2\\\\cours\\\\aide décision\\\\knowledge_distillation\\\\models\\\\pretrained_student_training\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 10/10 [00:21<00:00,  0.47it/s, v_num=1, train_loss_step=0.797, train_f1_score_step=0.481, validation_loss=0.959, validation_f1_score=0.483, train_loss_epoch=0.852, train_f1_score_epoch=0.455]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 40: 'validation_f1_score' reached 0.48326 (best 0.48326), saving model to 'C:\\\\paris_cite\\\\m2\\\\cours\\\\aide décision\\\\knowledge_distillation\\\\models\\\\pretrained_student_training\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 10/10 [00:21<00:00,  0.46it/s, v_num=1, train_loss_step=0.645, train_f1_score_step=0.528, validation_loss=0.842, validation_f1_score=0.529, train_loss_epoch=0.678, train_f1_score_epoch=0.507]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 50: 'validation_f1_score' reached 0.52933 (best 0.52933), saving model to 'C:\\\\paris_cite\\\\m2\\\\cours\\\\aide décision\\\\knowledge_distillation\\\\models\\\\pretrained_student_training\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 10/10 [00:19<00:00,  0.50it/s, v_num=1, train_loss_step=0.518, train_f1_score_step=0.564, validation_loss=0.808, validation_f1_score=0.565, train_loss_epoch=0.548, train_f1_score_epoch=0.548]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 60: 'validation_f1_score' reached 0.56510 (best 0.56510), saving model to 'C:\\\\paris_cite\\\\m2\\\\cours\\\\aide décision\\\\knowledge_distillation\\\\models\\\\pretrained_student_training\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 10/10 [00:18<00:00,  0.54it/s, v_num=1, train_loss_step=0.407, train_f1_score_step=0.593, validation_loss=0.793, validation_f1_score=0.594, train_loss_epoch=0.441, train_f1_score_epoch=0.580]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 70: 'validation_f1_score' reached 0.59381 (best 0.59381), saving model to 'C:\\\\paris_cite\\\\m2\\\\cours\\\\aide décision\\\\knowledge_distillation\\\\models\\\\pretrained_student_training\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 10/10 [00:18<00:00,  0.54it/s, v_num=1, train_loss_step=0.351, train_f1_score_step=0.616, validation_loss=0.797, validation_f1_score=0.617, train_loss_epoch=0.346, train_f1_score_epoch=0.606]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 80: 'validation_f1_score' reached 0.61718 (best 0.61718), saving model to 'C:\\\\paris_cite\\\\m2\\\\cours\\\\aide décision\\\\knowledge_distillation\\\\models\\\\pretrained_student_training\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 10/10 [00:18<00:00,  0.55it/s, v_num=1, train_loss_step=0.263, train_f1_score_step=0.636, validation_loss=0.826, validation_f1_score=0.637, train_loss_epoch=0.265, train_f1_score_epoch=0.627]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 90: 'validation_f1_score' reached 0.63675 (best 0.63675), saving model to 'C:\\\\paris_cite\\\\m2\\\\cours\\\\aide décision\\\\knowledge_distillation\\\\models\\\\pretrained_student_training\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 10/10 [00:18<00:00,  0.54it/s, v_num=1, train_loss_step=0.185, train_f1_score_step=0.653, validation_loss=0.849, validation_f1_score=0.653, train_loss_epoch=0.195, train_f1_score_epoch=0.646]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 100: 'validation_f1_score' reached 0.65338 (best 0.65338), saving model to 'C:\\\\paris_cite\\\\m2\\\\cours\\\\aide décision\\\\knowledge_distillation\\\\models\\\\pretrained_student_training\\\\best.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 10/10 [00:18<00:00,  0.53it/s, v_num=1, train_loss_step=0.185, train_f1_score_step=0.653, validation_loss=0.849, validation_f1_score=0.653, train_loss_epoch=0.195, train_f1_score_epoch=0.646]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model=studentResnet18, train_dataloaders=train_dataloader, val_dataloaders=validation_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 3/3 [00:00<00:00,  3.95it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_f1_score         0.6541073322296143\n",
      "        test_loss           0.8343192338943481\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.8343192338943481, 'test_f1_score': 0.6541073322296143}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the student model.\n",
    "trainer.test(model=studentResnet18, dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of parameters for the student Resnet18 (extracted from training output).\n",
    "#  | Name     | Type   | Params | Mode \n",
    "#--------------------------------------------\n",
    "#0 | resnet18 | ResNet | 11.2 M | train\n",
    "#--------------------------------------------\n",
    "#11.2 M    Trainable params\n",
    "#0         Non-trainable params\n",
    "#11.2 M    Total params\n",
    "#44.727    Total estimated model params size (MB)\n",
    "#94        Modules in train mode\n",
    "#0         Modules in eval mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training results comparison\n",
    " \n",
    "Teacher model f1 score : 70.22%\n",
    "\n",
    "Student model f1 score : 65.41%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform distillation based on scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistilledStudentResnet18(L.LightningModule):\n",
    "    def __init__(self, num_classes : int,\n",
    "                 pretrained_student: bool = True,\n",
    "                 lr : float = 1e-4,\n",
    "                 temperature : float = 2,\n",
    "                 soft_target_loss_weight : float = 0.25,\n",
    "                 cross_entropy_loss_weight : float = 0.75) -> None:\n",
    "        \"\"\"A pytorch lightning implementation of the distillation process for the pretrained (or not) Resnet18 model.\n",
    "        Implementation is inspired from https://pytorch.org/tutorials/beginner/knowledge_distillation_tutorial.html\n",
    "        The teacher model is the fine-tuned Resnet50.\n",
    "\n",
    "        Args:\n",
    "            num_classes: The number of classes to set when replacing the final classification layer for fine-tuning purposes.\n",
    "            pretrained_student: A boolean value indicating whether to load the pre-trained weights of the student model. Defaults to true.\n",
    "            lr: The learning rate used during training. Defaults to 1e-4.\n",
    "            temperature : Controls the smoothness of the output distributions. Larger T leads to smoother distributions, thus smaller probabilities get a larger boost. Defaults to 2.\n",
    "            soft_target_loss_weight : A weight assigned to the loss calculated on the scores. Defaults to 0.25.\n",
    "            cross_entropy_loss_weight : A weight assigned to the cross entropy loss calculated on the targets. Defaults to 0.75.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Load the pre-trained (or not) student model.\n",
    "        studentResnet18 = TrainingStudentResNet18(num_classes=NUM_CLASSES,\n",
    "                                                  pretrained=pretrained_student,\n",
    "                                                  lr=lr)\n",
    "        self.student_resnet18 = studentResnet18.resnet18 # Extract the resnet18 model to get rid of the previous pytorch lightning training logic.\n",
    "        # Load the fine-tuned teacher model.\n",
    "        teacherResnet50 = TrainingTeacherResNet50.load_from_checkpoint(\"finetuned_models/pretrained_teacher_training/best.ckpt\",\n",
    "                                                                       num_classes=NUM_CLASSES,\n",
    "                                                                       pretrained=False)\n",
    "        self.teacherResnet50 = teacherResnet50.resnet50 # Extract the resnet50 model to get rid of the previous pytorch lightning training logic.\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.f1_metric = MulticlassF1Score(num_classes=num_classes)\n",
    "        self.temperature = temperature\n",
    "        self.soft_target_loss_weight = soft_target_loss_weight\n",
    "        self.cross_entropy_loss_weight = cross_entropy_loss_weight\n",
    "\n",
    "    def forward(self, input_tensor: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"This forward method runs the inference for both the teacher and the student model and returns their logits as a tuple (teacher_logits, student_logits).\"\"\"\n",
    "        with torch.no_grad(): #Freeze teacher model weights.\n",
    "            teacher_logits = self.teacherResnet50(input_tensor)\n",
    "        \n",
    "        student_logits = self.student_resnet18(input_tensor)\n",
    "        return teacher_logits, student_logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        self.teacherResnet50.eval()\n",
    "        # training_step defines the train loop.\n",
    "        input_batch, target_batch = batch\n",
    "        teacher_logits, student_logits = self(input_batch)\n",
    "        #Soften the logits using the temperature.\n",
    "        soft_targets = torch.nn.functional.softmax(teacher_logits / self.temperature, dim=-1)\n",
    "        soft_prob = torch.nn.functional.log_softmax(student_logits / self.temperature, dim=-1)\n",
    "\n",
    "        soft_targets_loss = torch.sum(soft_targets * (soft_targets.log() - soft_prob)) / soft_prob.size()[0] * (self.temperature**2)\n",
    "\n",
    "        cross_entropy_loss = torch.nn.functional.cross_entropy(student_logits, target_batch)\n",
    "\n",
    "        #Calculate the weighted sum of the two losses.\n",
    "        loss = self.soft_target_loss_weight * soft_targets_loss + self.cross_entropy_loss_weight * cross_entropy_loss\n",
    "        #Calculate metrics\n",
    "        self.f1_metric.update(student_logits, target_batch)\n",
    "        train_f1_score = self.f1_metric.compute()\n",
    "        self.log(\"train_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train_f1_score\", train_f1_score, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # validation_step defines the validation loop.\n",
    "        input_batch, target_batch = batch\n",
    "        _, student_logits = self(input_batch)\n",
    "        loss = torch.nn.functional.cross_entropy(student_logits, target_batch)\n",
    "        #Calculate metrics\n",
    "        self.f1_metric.update(student_logits, target_batch)\n",
    "        validation_f1_score = self.f1_metric.compute()\n",
    "        self.log(\"validation_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"validation_f1_score\", validation_f1_score, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # test_step defines the test loop.\n",
    "        input_batch, target_batch = batch\n",
    "        _, student_logits= self(input_batch)\n",
    "        loss = torch.nn.functional.cross_entropy(student_logits, target_batch)\n",
    "        #Calculate metrics\n",
    "        self.f1_metric.update(student_logits, target_batch)\n",
    "        test_f1_score = self.f1_metric.compute()\n",
    "        self.log(\"test_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"test_f1_score\", test_f1_score, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the distillation model.\n",
    "torch.manual_seed(MANUAL_SEED) # Seed the weights for the new classification layer of the student model.\n",
    "distilled_student_resnet18 = DistilledStudentResnet18(num_classes=NUM_CLASSES,\n",
    "                                                      pretrained_student=True,\n",
    "                                                      lr=LEARNINIG_RATE,\n",
    "                                                      temperature=2,\n",
    "                                                      soft_target_loss_weight=0.1,\n",
    "                                                      cross_entropy_loss_weight=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1)` was configured so validation will run after every batch.\n"
     ]
    }
   ],
   "source": [
    "# Only save to disk the best performing version of the student model throughout training (best f1 score).\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=\"models/distilled_pretrained_student_training\",\n",
    "        monitor=\"validation_f1_score\",\n",
    "        filename=\"best\",\n",
    "        mode=\"max\",\n",
    "        save_last=False,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "trainer = L.Trainer(max_epochs=EPOCHS,\n",
    "                    log_every_n_steps=1,\n",
    "                    val_check_interval=1,\n",
    "                    callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type            | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | student_resnet18 | StudentResNet18 | 11.2 M | train\n",
      "1 | teacherResnet50  | TeacherResNet50 | 23.5 M | train\n",
      "-------------------------------------------------------------\n",
      "34.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "34.7 M    Total params\n",
      "138.841   Total estimated model params size (MB)\n",
      "313       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\paris_cite\\m2\\cours\\aide décision\\knowledge_distillation\\venv\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\paris_cite\\m2\\cours\\aide décision\\knowledge_distillation\\venv\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 10/10 [00:40<00:00,  0.25it/s, v_num=0, train_loss_step=2.580, train_f1_score_step=0.230, validation_loss=1.860, validation_f1_score=0.236, train_loss_epoch=2.870, train_f1_score_epoch=0.155]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 10: 'validation_f1_score' reached 0.23605 (best 0.23605), saving model to 'C:\\\\paris_cite\\\\m2\\\\cours\\\\aide décision\\\\knowledge_distillation\\\\models\\\\distilled_pretrained_student_training\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 10/10 [00:39<00:00,  0.26it/s, v_num=0, train_loss_step=1.780, train_f1_score_step=0.336, validation_loss=1.650, validation_f1_score=0.339, train_loss_epoch=2.110, train_f1_score_epoch=0.293]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 20: 'validation_f1_score' reached 0.33912 (best 0.33912), saving model to 'C:\\\\paris_cite\\\\m2\\\\cours\\\\aide décision\\\\knowledge_distillation\\\\models\\\\distilled_pretrained_student_training\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 10/10 [00:42<00:00,  0.23it/s, v_num=0, train_loss_step=1.300, train_f1_score_step=0.414, validation_loss=1.140, validation_f1_score=0.417, train_loss_epoch=1.470, train_f1_score_epoch=0.379]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 30: 'validation_f1_score' reached 0.41709 (best 0.41709), saving model to 'C:\\\\paris_cite\\\\m2\\\\cours\\\\aide décision\\\\knowledge_distillation\\\\models\\\\distilled_pretrained_student_training\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 10/10 [00:41<00:00,  0.24it/s, v_num=0, train_loss_step=0.995, train_f1_score_step=0.477, validation_loss=0.943, validation_f1_score=0.480, train_loss_epoch=1.120, train_f1_score_epoch=0.450]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 40: 'validation_f1_score' reached 0.47970 (best 0.47970), saving model to 'C:\\\\paris_cite\\\\m2\\\\cours\\\\aide décision\\\\knowledge_distillation\\\\models\\\\distilled_pretrained_student_training\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 10/10 [00:39<00:00,  0.25it/s, v_num=0, train_loss_step=0.861, train_f1_score_step=0.525, validation_loss=0.860, validation_f1_score=0.527, train_loss_epoch=0.890, train_f1_score_epoch=0.504]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 50: 'validation_f1_score' reached 0.52686 (best 0.52686), saving model to 'C:\\\\paris_cite\\\\m2\\\\cours\\\\aide décision\\\\knowledge_distillation\\\\models\\\\distilled_pretrained_student_training\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 10/10 [00:39<00:00,  0.25it/s, v_num=0, train_loss_step=0.698, train_f1_score_step=0.562, validation_loss=0.804, validation_f1_score=0.563, train_loss_epoch=0.719, train_f1_score_epoch=0.546]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 60: 'validation_f1_score' reached 0.56341 (best 0.56341), saving model to 'C:\\\\paris_cite\\\\m2\\\\cours\\\\aide décision\\\\knowledge_distillation\\\\models\\\\distilled_pretrained_student_training\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 10/10 [00:35<00:00,  0.28it/s, v_num=0, train_loss_step=0.545, train_f1_score_step=0.592, validation_loss=0.800, validation_f1_score=0.593, train_loss_epoch=0.580, train_f1_score_epoch=0.579]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 70: 'validation_f1_score' reached 0.59277 (best 0.59277), saving model to 'C:\\\\paris_cite\\\\m2\\\\cours\\\\aide décision\\\\knowledge_distillation\\\\models\\\\distilled_pretrained_student_training\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 10/10 [00:35<00:00,  0.28it/s, v_num=0, train_loss_step=0.424, train_f1_score_step=0.616, validation_loss=0.802, validation_f1_score=0.617, train_loss_epoch=0.462, train_f1_score_epoch=0.605]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 80: 'validation_f1_score' reached 0.61675 (best 0.61675), saving model to 'C:\\\\paris_cite\\\\m2\\\\cours\\\\aide décision\\\\knowledge_distillation\\\\models\\\\distilled_pretrained_student_training\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 10/10 [00:35<00:00,  0.28it/s, v_num=0, train_loss_step=0.346, train_f1_score_step=0.636, validation_loss=0.842, validation_f1_score=0.637, train_loss_epoch=0.359, train_f1_score_epoch=0.627]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 90: 'validation_f1_score' reached 0.63687 (best 0.63687), saving model to 'C:\\\\paris_cite\\\\m2\\\\cours\\\\aide décision\\\\knowledge_distillation\\\\models\\\\distilled_pretrained_student_training\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 10/10 [00:36<00:00,  0.28it/s, v_num=0, train_loss_step=0.261, train_f1_score_step=0.653, validation_loss=0.871, validation_f1_score=0.654, train_loss_epoch=0.279, train_f1_score_epoch=0.646]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 100: 'validation_f1_score' reached 0.65384 (best 0.65384), saving model to 'C:\\\\paris_cite\\\\m2\\\\cours\\\\aide décision\\\\knowledge_distillation\\\\models\\\\distilled_pretrained_student_training\\\\best.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 10/10 [00:37<00:00,  0.27it/s, v_num=0, train_loss_step=0.261, train_f1_score_step=0.653, validation_loss=0.871, validation_f1_score=0.654, train_loss_epoch=0.279, train_f1_score_epoch=0.646]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model=distilled_student_resnet18, train_dataloaders=train_dataloader, val_dataloaders=validation_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\paris_cite\\m2\\cours\\aide décision\\knowledge_distillation\\venv\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 3/3 [00:01<00:00,  1.57it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_f1_score         0.6546118855476379\n",
      "        test_loss           0.8495639562606812\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.8495639562606812, 'test_f1_score': 0.6546118855476379}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model=distilled_student_resnet18, dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training results comparison\n",
    " \n",
    "Teacher model f1 score : 70.22%\n",
    "\n",
    "Student model f1 score : 65.41%\n",
    "\n",
    "Distilled pretrained student model f1 score : 65.46%\n",
    "\n",
    "The scores distillation seems to have slightly improved the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform distillation based on scores and feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedTeacherResNet50(torch.nn.Module):\n",
    "    def __init__(self, num_classes : int, pretrained: bool = True) -> None:\n",
    "        \"\"\"An implementation of a fine-tunable Resnet50 pretrained (or not) model.\n",
    "        The final classification layer is replaced with a new one that predicts the number of classes defined by 'num_classes'.\n",
    "\n",
    "        Args:\n",
    "            num_classes: The number of classes to set when replacing the final classification layer for fine-tuning purposes.\n",
    "            pretrained: A boolean value indicating whether to load the pre-trained weights of the model. Defaults to true.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.resnet50 = timm.create_model('resnet50', pretrained=pretrained)\n",
    "        #Replace the final classification layer of the model for fine-tuning purposes.\n",
    "        self.resnet50.fc = torch.nn.Linear(\n",
    "            in_features=self.resnet50.fc.in_features,\n",
    "            out_features=num_classes\n",
    "        )\n",
    "        # A placeholder for feature maps.\n",
    "        self.feature_map = None\n",
    "        # Register a forward hook to capture feature maps from 'layer4'.\n",
    "        self.resnet50.layer4.register_forward_hook(self._hook_function)\n",
    "\n",
    "    def _hook_function(self, module, input, output):\n",
    "        \"\"\"A way of getting hold of the feature maps just before the flattening for classification.\n",
    "        A fine example of modern-day spaghetti engineering. But it works.\"\"\"\n",
    "        self.feature_map = output\n",
    "    \n",
    "    def forward(self, x):\n",
    "        logits = self.resnet50(x)\n",
    "        return logits, self.feature_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedStudentResNet18(torch.nn.Module):\n",
    "    def __init__(self, num_classes: int, pretrained: bool = True) -> None:\n",
    "        \"\"\"\n",
    "        An implementation of a fine-tunable ResNet18 pretrained (or not) model.\n",
    "        The final classification layer is replaced with a new one that predicts the number of classes defined by 'num_classes'.\n",
    "\n",
    "        Args:\n",
    "            num_classes: The number of classes to set when replacing the final classification layer for fine-tuning purposes.\n",
    "            pretrained: A boolean value indicating whether to load the pre-trained weights of the model. Defaults to true.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.resnet18 = timm.create_model('resnet18', pretrained=pretrained)\n",
    "        \n",
    "        # Replace the final classification layer of the model for fine-tuning purposes.\n",
    "        self.resnet18.fc = torch.nn.Linear(\n",
    "            in_features=self.resnet18.fc.in_features,\n",
    "            out_features=num_classes\n",
    "        )\n",
    "        \n",
    "        # Placeholder for feature maps.\n",
    "        self.feature_map = None\n",
    "        \n",
    "        # Add a regressor to align with the teacher's feature maps.\n",
    "        self.regressor = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(512, 2048, kernel_size=1),  # size of resnet18\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(2048, 2048, kernel_size=3, padding=1),  # to size of resnet50\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Register a forward hook to capture feature maps from 'layer4'.\n",
    "        self.resnet18.layer4.register_forward_hook(self._hook_fn)\n",
    "    \n",
    "    def _hook_fn(self, module, input, output):\n",
    "        \"\"\"A way of getting hold of the feature maps just before the flattening for classification.\n",
    "        A fine example of modern-day spaghetti engineering. But it works.\"\"\"\n",
    "        self.feature_map = output\n",
    "    \n",
    "    def forward(self, x):\n",
    "        logits = self.resnet18(x)\n",
    "        regressed_features = self.regressor(self.feature_map)\n",
    "        return logits, regressed_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : STOPPED HERE\n",
    "class FeatureMapDistilledStudentResnet18(L.LightningModule):\n",
    "    def __init__(self, num_classes : int,\n",
    "                 pretrained_student: bool = True,\n",
    "                 lr : float = 1e-4,\n",
    "                 temperature : float = 2,\n",
    "                 soft_target_loss_weight : float = 0.25,\n",
    "                 cross_entropy_loss_weight : float = 0.75) -> None:\n",
    "        \"\"\"A pytorch lightning implementation of the feature map distillation process for the pretrained (or not) Resnet18 model.\n",
    "        Implementation is inspired from https://pytorch.org/tutorials/beginner/knowledge_distillation_tutorial.html\n",
    "        The teacher model is the fine-tuned Resnet50.\n",
    "\n",
    "        Args:\n",
    "            num_classes: The number of classes to set when replacing the final classification layer for fine-tuning purposes.\n",
    "            pretrained_student: A boolean value indicating whether to load the pre-trained weights of the student model. Defaults to true.\n",
    "            lr: The learning rate used during training. Defaults to 1e-4.\n",
    "            temperature : Controls the smoothness of the output distributions. Larger T leads to smoother distributions, thus smaller probabilities get a larger boost. Defaults to 2.\n",
    "            soft_target_loss_weight : A weight assigned to the loss calculated on the scores. Defaults to 0.25.\n",
    "            cross_entropy_loss_weight : A weight assigned to the cross entropy loss calculated on the targets. Defaults to 0.75.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Load the pre-trained (or not) student model.\n",
    "        studentResnet18 = TrainingStudentResNet18(num_classes=NUM_CLASSES,\n",
    "                                                  pretrained=pretrained_student,\n",
    "                                                  lr=lr)\n",
    "        self.student_resnet18 = studentResnet18.resnet18 # Extract the resnet18 model to get rid of the previous pytorch lightning training logic.\n",
    "        # Load the fine-tuned teacher model.\n",
    "        teacherResnet50 = TrainingTeacherResNet50.load_from_checkpoint(\"finetuned_models/pretrained_teacher_training/best.ckpt\",\n",
    "                                                                       num_classes=NUM_CLASSES,\n",
    "                                                                       pretrained=False)\n",
    "        self.teacherResnet50 = teacherResnet50.resnet50 # Extract the resnet50 model to get rid of the previous pytorch lightning training logic.\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.f1_metric = MulticlassF1Score(num_classes=num_classes)\n",
    "        self.temperature = temperature\n",
    "        self.soft_target_loss_weight = soft_target_loss_weight\n",
    "        self.cross_entropy_loss_weight = cross_entropy_loss_weight\n",
    "\n",
    "    def forward(self, input_tensor: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"This forward method runs the inference for both the teacher and the student model and returns their logits as a tuple (teacher_logits, student_logits).\"\"\"\n",
    "        with torch.no_grad(): #Freeze teacher model weights.\n",
    "            teacher_logits = self.teacherResnet50(input_tensor)\n",
    "        \n",
    "        student_logits = self.student_resnet18(input_tensor)\n",
    "        return teacher_logits, student_logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        self.teacherResnet50.eval()\n",
    "        # training_step defines the train loop.\n",
    "        input_batch, target_batch = batch\n",
    "        teacher_logits, student_logits = self(input_batch)\n",
    "        #Soften the logits using the temperature.\n",
    "        soft_targets = torch.nn.functional.softmax(teacher_logits / self.temperature, dim=-1)\n",
    "        soft_prob = torch.nn.functional.log_softmax(student_logits / self.temperature, dim=-1)\n",
    "\n",
    "        soft_targets_loss = torch.sum(soft_targets * (soft_targets.log() - soft_prob)) / soft_prob.size()[0] * (self.temperature**2)\n",
    "\n",
    "        cross_entropy_loss = torch.nn.functional.cross_entropy(student_logits, target_batch)\n",
    "\n",
    "        #Calculate the weighted sum of the two losses.\n",
    "        loss = self.soft_target_loss_weight * soft_targets_loss + self.cross_entropy_loss_weight * cross_entropy_loss\n",
    "        #Calculate metrics\n",
    "        self.f1_metric.update(student_logits, target_batch)\n",
    "        train_f1_score = self.f1_metric.compute()\n",
    "        self.log(\"train_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train_f1_score\", train_f1_score, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # validation_step defines the validation loop.\n",
    "        input_batch, target_batch = batch\n",
    "        _, student_logits = self(input_batch)\n",
    "        loss = torch.nn.functional.cross_entropy(student_logits, target_batch)\n",
    "        #Calculate metrics\n",
    "        self.f1_metric.update(student_logits, target_batch)\n",
    "        validation_f1_score = self.f1_metric.compute()\n",
    "        self.log(\"validation_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"validation_f1_score\", validation_f1_score, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # test_step defines the test loop.\n",
    "        input_batch, target_batch = batch\n",
    "        _, student_logits= self(input_batch)\n",
    "        loss = torch.nn.functional.cross_entropy(student_logits, target_batch)\n",
    "        #Calculate metrics\n",
    "        self.f1_metric.update(student_logits, target_batch)\n",
    "        test_f1_score = self.f1_metric.compute()\n",
    "        self.log(\"test_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"test_f1_score\", test_f1_score, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategy 2 : Knowledge distillation using a non pre-trained student"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the non pre-trained student network on CIFAR 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the pre-trained student model with 10 classes for the classifier.\n",
    "torch.manual_seed(MANUAL_SEED) # Seed the weights for the new classification layer.\n",
    "studentResnet18 = TrainingStudentResNet18(num_classes=10,\n",
    "                                          pretrained=False, # Do not load the weights learned from pre-training on ImageNet.\n",
    "                                          lr=LEARNINIG_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1)` was configured so validation will run after every batch.\n"
     ]
    }
   ],
   "source": [
    "# Only save to disk the best performing version of the model throughout training (best f1 score).\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=\"models/non_pretrained_student_training\",\n",
    "        monitor=\"validation_f1_score\",\n",
    "        filename=\"best\",\n",
    "        mode=\"max\",\n",
    "        save_last=False,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "trainer = L.Trainer(max_epochs=EPOCHS,\n",
    "                    log_every_n_steps=1,\n",
    "                    val_check_interval=1,\n",
    "                    callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type            | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | resnet18 | StudentResNet18 | 11.2 M | train\n",
      "-----------------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.727    Total estimated model params size (MB)\n",
      "95        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\paris_cite\\m2\\cours\\aide décision\\knowledge_distillation\\venv\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\paris_cite\\m2\\cours\\aide décision\\knowledge_distillation\\venv\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 10/10 [00:20<00:00,  0.48it/s, v_num=0, train_loss_step=2.030, train_f1_score_step=0.155, validation_loss=2.230, validation_f1_score=0.154, train_loss_epoch=2.140, train_f1_score_epoch=0.150]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 10: 'validation_f1_score' reached 0.15416 (best 0.15416), saving model to 'C:\\\\paris_cite\\\\m2\\\\cours\\\\aide décision\\\\knowledge_distillation\\\\models\\\\non_pretrained_student_training\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 10/10 [00:19<00:00,  0.50it/s, v_num=0, train_loss_step=1.820, train_f1_score_step=0.178, validation_loss=2.230, validation_f1_score=0.178, train_loss_epoch=1.920, train_f1_score_epoch=0.166]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 20: 'validation_f1_score' reached 0.17791 (best 0.17791), saving model to 'C:\\\\paris_cite\\\\m2\\\\cours\\\\aide décision\\\\knowledge_distillation\\\\models\\\\non_pretrained_student_training\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 10/10 [00:19<00:00,  0.51it/s, v_num=0, train_loss_step=1.500, train_f1_score_step=0.211, validation_loss=1.980, validation_f1_score=0.212, train_loss_epoch=1.620, train_f1_score_epoch=0.195]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 30: 'validation_f1_score' reached 0.21246 (best 0.21246), saving model to 'C:\\\\paris_cite\\\\m2\\\\cours\\\\aide décision\\\\knowledge_distillation\\\\models\\\\non_pretrained_student_training\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 10/10 [00:20<00:00,  0.48it/s, v_num=0, train_loss_step=1.280, train_f1_score_step=0.257, validation_loss=1.530, validation_f1_score=0.259, train_loss_epoch=1.350, train_f1_score_epoch=0.235]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 40: 'validation_f1_score' reached 0.25903 (best 0.25903), saving model to 'C:\\\\paris_cite\\\\m2\\\\cours\\\\aide décision\\\\knowledge_distillation\\\\models\\\\non_pretrained_student_training\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 10/10 [00:21<00:00,  0.47it/s, v_num=0, train_loss_step=1.140, train_f1_score_step=0.306, validation_loss=1.310, validation_f1_score=0.308, train_loss_epoch=1.180, train_f1_score_epoch=0.284]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 50: 'validation_f1_score' reached 0.30827 (best 0.30827), saving model to 'C:\\\\paris_cite\\\\m2\\\\cours\\\\aide décision\\\\knowledge_distillation\\\\models\\\\non_pretrained_student_training\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 10/10 [00:20<00:00,  0.48it/s, v_num=0, train_loss_step=1.010, train_f1_score_step=0.350, validation_loss=1.190, validation_f1_score=0.352, train_loss_epoch=1.040, train_f1_score_epoch=0.331]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 60: 'validation_f1_score' reached 0.35219 (best 0.35219), saving model to 'C:\\\\paris_cite\\\\m2\\\\cours\\\\aide décision\\\\knowledge_distillation\\\\models\\\\non_pretrained_student_training\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 10/10 [00:20<00:00,  0.50it/s, v_num=0, train_loss_step=0.908, train_f1_score_step=0.388, validation_loss=1.130, validation_f1_score=0.389, train_loss_epoch=0.917, train_f1_score_epoch=0.371]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 70: 'validation_f1_score' reached 0.38925 (best 0.38925), saving model to 'C:\\\\paris_cite\\\\m2\\\\cours\\\\aide décision\\\\knowledge_distillation\\\\models\\\\non_pretrained_student_training\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 10/10 [00:20<00:00,  0.50it/s, v_num=0, train_loss_step=0.796, train_f1_score_step=0.420, validation_loss=1.080, validation_f1_score=0.421, train_loss_epoch=0.795, train_f1_score_epoch=0.406]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 80: 'validation_f1_score' reached 0.42085 (best 0.42085), saving model to 'C:\\\\paris_cite\\\\m2\\\\cours\\\\aide décision\\\\knowledge_distillation\\\\models\\\\non_pretrained_student_training\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 10/10 [00:20<00:00,  0.50it/s, v_num=0, train_loss_step=0.704, train_f1_score_step=0.447, validation_loss=1.110, validation_f1_score=0.448, train_loss_epoch=0.679, train_f1_score_epoch=0.435]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 90: 'validation_f1_score' reached 0.44765 (best 0.44765), saving model to 'C:\\\\paris_cite\\\\m2\\\\cours\\\\aide décision\\\\knowledge_distillation\\\\models\\\\non_pretrained_student_training\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 10/10 [00:20<00:00,  0.49it/s, v_num=0, train_loss_step=0.559, train_f1_score_step=0.469, validation_loss=1.120, validation_f1_score=0.470, train_loss_epoch=0.580, train_f1_score_epoch=0.459]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 100: 'validation_f1_score' reached 0.47025 (best 0.47025), saving model to 'C:\\\\paris_cite\\\\m2\\\\cours\\\\aide décision\\\\knowledge_distillation\\\\models\\\\non_pretrained_student_training\\\\best.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 10/10 [00:20<00:00,  0.48it/s, v_num=0, train_loss_step=0.559, train_f1_score_step=0.469, validation_loss=1.120, validation_f1_score=0.470, train_loss_epoch=0.580, train_f1_score_epoch=0.459]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model=studentResnet18, train_dataloaders=train_dataloader, val_dataloaders=validation_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 3/3 [00:00<00:00,  3.13it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_f1_score          0.47136390209198\n",
      "        test_loss           1.1162725687026978\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 1.1162725687026978, 'test_f1_score': 0.47136390209198}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the student model.\n",
    "trainer.test(model=studentResnet18, dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training results comparison\n",
    " \n",
    "Teacher model f1 score : 70.22%\n",
    "\n",
    "Non pre-trained student model f1 score : 47.13%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform distilation based on scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the distillation model.\n",
    "torch.manual_seed(MANUAL_SEED) # Seed the weights for the new classification layer of the student model.\n",
    "distilled_student_resnet18 = DistilledStudentResnet18(num_classes=NUM_CLASSES,\n",
    "                                                      pretrained_student=False,\n",
    "                                                      lr=LEARNINIG_RATE,\n",
    "                                                      temperature=2,\n",
    "                                                      soft_target_loss_weight=0.1,\n",
    "                                                      cross_entropy_loss_weight=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1)` was configured so validation will run after every batch.\n"
     ]
    }
   ],
   "source": [
    "# Only save to disk the best performing version of the student model throughout training (best f1 score).\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=\"models/distilled_non_pretrained_student_training\",\n",
    "        monitor=\"validation_f1_score\",\n",
    "        filename=\"best\",\n",
    "        mode=\"max\",\n",
    "        save_last=False,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "trainer = L.Trainer(max_epochs=EPOCHS,\n",
    "                    log_every_n_steps=1,\n",
    "                    val_check_interval=1,\n",
    "                    callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type            | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | student_resnet18 | StudentResNet18 | 11.2 M | train\n",
      "1 | teacherResnet50  | TeacherResNet50 | 23.5 M | train\n",
      "-------------------------------------------------------------\n",
      "34.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "34.7 M    Total params\n",
      "138.841   Total estimated model params size (MB)\n",
      "313       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 10/10 [00:34<00:00,  0.29it/s, v_num=0, train_loss_step=2.700, train_f1_score_step=0.154, validation_loss=2.230, validation_f1_score=0.153, train_loss_epoch=2.820, train_f1_score_epoch=0.149]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 10: 'validation_f1_score' reached 0.15293 (best 0.15293), saving model to 'C:\\\\paris_cite\\\\m2\\\\cours\\\\aide décision\\\\knowledge_distillation\\\\models\\\\distilled_non_pretrained_student_training\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 10/10 [00:34<00:00,  0.29it/s, v_num=0, train_loss_step=2.400, train_f1_score_step=0.176, validation_loss=2.230, validation_f1_score=0.177, train_loss_epoch=2.540, train_f1_score_epoch=0.165]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 20: 'validation_f1_score' reached 0.17681 (best 0.17681), saving model to 'C:\\\\paris_cite\\\\m2\\\\cours\\\\aide décision\\\\knowledge_distillation\\\\models\\\\distilled_non_pretrained_student_training\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 10/10 [00:34<00:00,  0.29it/s, v_num=0, train_loss_step=1.950, train_f1_score_step=0.213, validation_loss=1.940, validation_f1_score=0.214, train_loss_epoch=2.150, train_f1_score_epoch=0.196]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 30: 'validation_f1_score' reached 0.21436 (best 0.21436), saving model to 'C:\\\\paris_cite\\\\m2\\\\cours\\\\aide décision\\\\knowledge_distillation\\\\models\\\\distilled_non_pretrained_student_training\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 10/10 [00:34<00:00,  0.29it/s, v_num=0, train_loss_step=1.670, train_f1_score_step=0.261, validation_loss=1.560, validation_f1_score=0.263, train_loss_epoch=1.800, train_f1_score_epoch=0.238]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 40: 'validation_f1_score' reached 0.26288 (best 0.26288), saving model to 'C:\\\\paris_cite\\\\m2\\\\cours\\\\aide décision\\\\knowledge_distillation\\\\models\\\\distilled_non_pretrained_student_training\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 10/10 [00:36<00:00,  0.27it/s, v_num=0, train_loss_step=1.520, train_f1_score_step=0.311, validation_loss=1.310, validation_f1_score=0.313, train_loss_epoch=1.570, train_f1_score_epoch=0.288]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 50: 'validation_f1_score' reached 0.31268 (best 0.31268), saving model to 'C:\\\\paris_cite\\\\m2\\\\cours\\\\aide décision\\\\knowledge_distillation\\\\models\\\\distilled_non_pretrained_student_training\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 10/10 [00:36<00:00,  0.27it/s, v_num=0, train_loss_step=1.310, train_f1_score_step=0.354, validation_loss=1.230, validation_f1_score=0.356, train_loss_epoch=1.380, train_f1_score_epoch=0.335]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 60: 'validation_f1_score' reached 0.35574 (best 0.35574), saving model to 'C:\\\\paris_cite\\\\m2\\\\cours\\\\aide décision\\\\knowledge_distillation\\\\models\\\\distilled_non_pretrained_student_training\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 10/10 [00:35<00:00,  0.28it/s, v_num=0, train_loss_step=1.130, train_f1_score_step=0.390, validation_loss=1.200, validation_f1_score=0.392, train_loss_epoch=1.210, train_f1_score_epoch=0.374]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 70: 'validation_f1_score' reached 0.39163 (best 0.39163), saving model to 'C:\\\\paris_cite\\\\m2\\\\cours\\\\aide décision\\\\knowledge_distillation\\\\models\\\\distilled_non_pretrained_student_training\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 10/10 [00:35<00:00,  0.28it/s, v_num=0, train_loss_step=1.050, train_f1_score_step=0.421, validation_loss=1.130, validation_f1_score=0.422, train_loss_epoch=1.060, train_f1_score_epoch=0.407]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 80: 'validation_f1_score' reached 0.42208 (best 0.42208), saving model to 'C:\\\\paris_cite\\\\m2\\\\cours\\\\aide décision\\\\knowledge_distillation\\\\models\\\\distilled_non_pretrained_student_training\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 10/10 [00:34<00:00,  0.29it/s, v_num=0, train_loss_step=0.861, train_f1_score_step=0.447, validation_loss=1.140, validation_f1_score=0.448, train_loss_epoch=0.902, train_f1_score_epoch=0.436]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 90: 'validation_f1_score' reached 0.44829 (best 0.44829), saving model to 'C:\\\\paris_cite\\\\m2\\\\cours\\\\aide décision\\\\knowledge_distillation\\\\models\\\\distilled_non_pretrained_student_training\\\\best.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 10/10 [00:37<00:00,  0.27it/s, v_num=0, train_loss_step=0.747, train_f1_score_step=0.471, validation_loss=1.160, validation_f1_score=0.471, train_loss_epoch=0.753, train_f1_score_epoch=0.460]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 100: 'validation_f1_score' reached 0.47142 (best 0.47142), saving model to 'C:\\\\paris_cite\\\\m2\\\\cours\\\\aide décision\\\\knowledge_distillation\\\\models\\\\distilled_non_pretrained_student_training\\\\best.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 10/10 [00:39<00:00,  0.26it/s, v_num=0, train_loss_step=0.747, train_f1_score_step=0.471, validation_loss=1.160, validation_f1_score=0.471, train_loss_epoch=0.753, train_f1_score_epoch=0.460]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model=distilled_student_resnet18, train_dataloaders=train_dataloader, val_dataloaders=validation_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 3/3 [00:03<00:00,  0.88it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_f1_score         0.47255751490592957\n",
      "        test_loss           1.1684184074401855\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 1.1684184074401855, 'test_f1_score': 0.47255751490592957}]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model=distilled_student_resnet18, dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training results comparison\n",
    " \n",
    "Teacher model f1 score : 70.22%\n",
    "\n",
    "Non pre-trained student model f1 score : 47.13%\n",
    "\n",
    "Distilled non pre-trained student model f1 score : 47.25%\n",
    "\n",
    "The distillation process gave us slightly improved results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform distillation based on scores and feature maps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
